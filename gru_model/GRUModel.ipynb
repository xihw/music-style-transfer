{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pypianoroll as pr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.saved_model import tag_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(folder):\n",
    "    rawData = []\n",
    "    for filename in os.listdir(folder):\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        rawData.append(pr.parse(filepath).tracks[0].pianoroll / 128.)\n",
    "    return rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareMiniBatches(rawData, Tx = 1024):\n",
    "    mbs = []\n",
    "    for dat in rawData:\n",
    "        m = dat.shape[0]\n",
    "        nslices = (m + Tx - 1) // Tx\n",
    "        temp = np.pad(dat, ((0, nslices * Tx - m), (0, 0)), 'constant', constant_values = ((0,0), (0,0)))\n",
    "        mbs += np.split(temp, nslices, axis=0)\n",
    "    return np.array(mbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = loadDataSet('./data/jazz')\n",
    "mbs = prepareMiniBatches(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (mbs > 0) * 1.0\n",
    "Y = mbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDenseNet(inputs, struct, keepProb=1.):\n",
    "    if not isinstance(struct[0], (list, tuple)):\n",
    "        struct = [(u, 'relu') for u in struct]\n",
    "    densors = [tf.layers.Dense(u, activation=a, kernel_initializer=tf.contrib.layers.xavier_initializer()) for u, a in struct]\n",
    "    dropouts = [tf.layers.Dropout(keepProb) for u, a in struct]\n",
    "    X = inputs\n",
    "    for densor, dropout in zip(densors, dropouts):\n",
    "        X = densor(X)\n",
    "        X = dropout(X)         \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN():\n",
    "    def __init__(self, input_size=128, structEncode = [512, 256, 128], useRNNEncode = True, useGRU=False,\n",
    "                 rnn_unit=256, structDecode = [(512, 'relu'), (256, 'relu'), (128, 'sigmoid')], \n",
    "                 output_size=128, keep_prob=1, alphaZero = 10):\n",
    "        self.useRNNEncode = useRNNEncode\n",
    "        self.input_size = input_size\n",
    "        self.structEncode = structEncode\n",
    "        self.rnn_unit = rnn_unit\n",
    "        self.structDecode = structDecode\n",
    "        self.output_size = output_size\n",
    "        self.keep_prob = keep_prob\n",
    "        self.alphaZero = alphaZero\n",
    "        self.useGRU = useGRU\n",
    "        \n",
    "    def prepare(self):\n",
    "        # reset graph\n",
    "        tf.reset_default_graph()\n",
    "    \n",
    "        # input output unit\n",
    "        self.inputs = tf.placeholder(tf.float32, (None, None, self.input_size))\n",
    "        self.y_true = tf.placeholder(tf.float32, (None, None, self.output_size))\n",
    "    \n",
    "        # length of each piece of music\n",
    "        self.seq_len = tf.placeholder(tf.int32, [None])\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "        # build encode net\n",
    "        with tf.variable_scope(\"encode\"):\n",
    "            \n",
    "            if self.structEncode == None:\n",
    "                rnnInputs = self.inputs\n",
    "            else:\n",
    "                rnnInputs = buildDenseNet(self.inputs, self.structEncode, self.keep_prob)\n",
    "                \n",
    "            if self.useRNNEncode:\n",
    "                if self.useGRU:\n",
    "                    rnn_cell = tf.contrib.rnn.GRUCell(self.rnn_unit)\n",
    "                else:\n",
    "                    rnn_cell = tf.contrib.rnn.RNNCell(self.rnn_unit)\n",
    "                rnn_cell = tf.contrib.rnn.DropoutWrapper(rnn_cell,\n",
    "                                                          input_keep_prob=self.keep_prob,\n",
    "                                                          output_keep_prob=self.keep_prob)\n",
    "                # link rnn cells\n",
    "                self.encode,  rnn_state = tf.nn.dynamic_rnn(rnn_cell, rnnInputs, sequence_length=self.seq_len, dtype=tf.float32)\n",
    "        \n",
    "        # rnn cell with dropouts\n",
    "        with tf.variable_scope(\"core\"):\n",
    "            if self.useGRU:\n",
    "                self.rnn_cell = tf.contrib.rnn.GRUCell(self.rnn_unit)\n",
    "            else:    \n",
    "                self.rnn_cell = tf.contrib.rnn.RNNCell(self.rnn_unit)\n",
    "            self.rnn_cell = tf.contrib.rnn.DropoutWrapper(self.rnn_cell,\n",
    "                                                           input_keep_prob=self.keep_prob, \n",
    "                                                           output_keep_prob=self.keep_prob)\n",
    "\n",
    "            # link rnn cells\n",
    "            self.rnn_out, self.rnn_state = tf.nn.dynamic_rnn(self.rnn_cell, \n",
    "                                                               self.encode, \n",
    "                                                               sequence_length = self.seq_len,\n",
    "                                                               dtype = tf.float32)\n",
    "        \n",
    "        \n",
    "        # build output layers\n",
    "        with tf.variable_scope(\"output\"):\n",
    "            self.y_pred = buildDenseNet(self.rnn_out, self.structDecode, self.keep_prob)\n",
    "        \n",
    "    \n",
    "        self.defNewCost()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "    \n",
    "        \n",
    "    def defNewCost(self):\n",
    "        \n",
    "        notes = self.inputs\n",
    "        nNotes = tf.reduce_sum(notes)\n",
    "        emptyNotes = tf.to_float(tf.equal(self.inputs, 0))\n",
    "        nZeros = tf.reduce_sum(emptyNotes)\n",
    "        \n",
    "        #loss\n",
    "        squreDiff = tf.square(self.y_true - self.y_pred)\n",
    "        zeroLoss = tf.reduce_sum(tf.multiply(emptyNotes, squreDiff)) / nZeros\n",
    "        oneLoss = tf.reduce_sum(tf.multiply(notes, squreDiff)) / nNotes\n",
    "        self.cost = zeroLoss * self.alphaZero + oneLoss\n",
    "    \n",
    "    def train(self, X, Y, batch = 512, epochs=100, learning_rate=0.001):\n",
    "        \n",
    "        m = X.shape[0]\n",
    "        Tx = X.shape[1]\n",
    "        seq_len = [Tx] * batch\n",
    "        \n",
    "        \n",
    "        nBatch = (m + batch - 1) // batch\n",
    "        idxs = np.array_split(np.random.permutation(m), nBatch)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(epochs):\n",
    "            for idx in idxs:\n",
    "                _, cost = self.sess.run([self.optimizer, self.cost], \n",
    "                                       feed_dict={\n",
    "                                           self.inputs : X[idx, :, :],\n",
    "                                           self.y_true: Y[idx, :, :],\n",
    "                                           self.seq_len : [Tx] * len(idx),\n",
    "                                           self.learning_rate : learning_rate\n",
    "                                       })                \n",
    "            print(epoch, cost)\n",
    "            self.trainingLog(epoch, cost)\n",
    "                \n",
    "                \n",
    "    def predict(self, x):\n",
    "        \n",
    "        m = x.shape[0]\n",
    "        t_x = x.shape[1]\n",
    "        seq_len = [t_x] * m\n",
    "    \n",
    "\n",
    "        return self.sess.run([self.y_pred], \n",
    "                             feed_dict={\n",
    "                                 self.inputs : x,\n",
    "                                 self.seq_len : seq_len\n",
    "                             })\n",
    "    \n",
    "    def loadModel(self, folder):\n",
    "        \n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "            self.sess = tf.Session()\n",
    "            tf.saved_model.loader.load(\n",
    "                self.sess,\n",
    "                [tag_constants.SERVING],\n",
    "                folder,\n",
    "            )\n",
    "            self.y_pred = graph.get_tensor_by_name('output/dense_2/Sigmoid:0')\n",
    "            self.inputs = graph.get_tensor_by_name('Placeholder:0')\n",
    "            self.y_true = graph.get_tensor_by_name('Placeholder_1:0')\n",
    "            self.seq_len = graph.get_tensor_by_name('Placeholder_2:0')\n",
    "        \n",
    "            self.cost = graph.get_tensor_by_name('add:0')\n",
    "            self.optimizer = graph.get_operation_by_name('Adam')\n",
    "\n",
    "\n",
    "    \n",
    "    def init_tf(self):\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "        # Run the initialization\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def closeSess(self):\n",
    "        self.sess.close()\n",
    "        \n",
    "    def simpleSave(self, filename):\n",
    "        tf.saved_model.simple_save(self.sess, filename, \n",
    "                                   inputs={\"inputs\": self.inputs}, \n",
    "                                   outputs={\"outputs\": self.y_pred})\n",
    "\n",
    "    def trainingLog(self, epoch, cost):\n",
    "        with open('trainingLog.txt', 'a') as f:\n",
    "            f.write(str(epoch)+', '+ str(cost))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(alphaZero=0.01, useRNNEncode=True, useGRU=True, keep_prob=1)#, structDecode=[(128, 'sigmoid')])\n",
    "model.prepare()\n",
    "model.init_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSongs = 3072\n",
    "pred_y = model.train(X[:nSongs, :, :], Y[:nSongs, :, :], batch=128, epochs=100, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summaryStats(y_pred, y_true):\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    y_true_flat = y_true.flatten()\n",
    "    \n",
    "    idx_notes = (y_true_flat > 0)\n",
    "    idx_zeros = (y_true_flat == 0)\n",
    "    \n",
    "    pred_vel, true_vel = y_pred_flat[idx_notes], y_true_flat[idx_notes]\n",
    "    pred_zeros = y_pred_flat[idx_zeros]\n",
    "    \n",
    "    return pred_vel, true_vel, pred_zeros\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X[2072:2074, :, :] \n",
    "Y_sample = Y[2072:2074, :, :] \n",
    "model.predict(X_sample)\n",
    "y_pred = model.predict(X_sample)[0] * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vel, true_vel, pred_zeros = summaryStats(y_pred[0], Y_sample[0] * 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (pred_vel - true_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(true_vel, pred_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(pred_zeros, bins=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.closeSess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_classical = pr.parse('./data/classical/beethoven_opus10_2_format0.mid')\n",
    "pr_input = (pr_classical.tracks[0].pianoroll > 0).reshape(1, -1, 128) * 1.\n",
    "pr_transferred = model.predict(pr_input)\n",
    "pr_transferred = pr_transferred * pr_input\n",
    "t = (pr_transferred * 128).round()\n",
    "pr_classical.tracks[0].pianoroll = t.reshape(-1, 128)\n",
    "pr_classical.write('./transfered_2.mid')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
